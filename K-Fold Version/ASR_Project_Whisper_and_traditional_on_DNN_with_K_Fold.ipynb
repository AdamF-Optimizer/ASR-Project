{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXdHuMT7K5or"
      },
      "outputs": [],
      "source": [
        "# ! pip install librosa\n",
        "# ! pip install parselmouth\n",
        "# ! pip install pyAudioAnalysis\n",
        "# ! pip install torch\n",
        "# ! pip install transformers\n",
        "# ! pip install pandas\n",
        "# ! pip install tqdm\n",
        "# ! pip install scikit-learn\n",
        "# ! pip install parselmouth\n",
        "# ! pip install nolds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fni6FlZtKC5P",
        "outputId": "a5e950a8-c8bb-4c38-8fa7-16bb793bcf24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Project'\n",
            "/content/Project\n"
          ]
        }
      ],
      "source": [
        "%cd Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa0bO-l17EdV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "import librosa\n",
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, precision_score, roc_auc_score, roc_curve, auc\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoFeatureExtractor, WhisperModel, AutoModelForAudioClassification\n",
        "import logging\n",
        "import gc\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nolds\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-VfFLIIKwYQ",
        "outputId": "79b35da6-181d-4959-dc3c-9dfd719c0c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8708 Parkinson files and 5349 Control files.\n"
          ]
        }
      ],
      "source": [
        "base_path = \"ParkCeleb_filtered\"\n",
        "groups = {\"PD\": 1, \"CN\": 0}\n",
        "\n",
        "parkinson_files = []\n",
        "control_files = []\n",
        "\n",
        "# Loop over each group (PD, CN)\n",
        "for group, label in groups.items():\n",
        "    group_path = os.path.join(base_path, group)\n",
        "    # Recursively search for any .wav file\n",
        "    wav_files = glob(os.path.join(group_path, \"**\", \"*.wav\"), recursive=True)\n",
        "\n",
        "    if label == 1:\n",
        "        parkinson_files.extend(wav_files)\n",
        "    else:\n",
        "        control_files.extend(wav_files)\n",
        "\n",
        "# Merge and create labels\n",
        "all_files = parkinson_files + control_files\n",
        "labels = [1] * len(parkinson_files) + [0] * len(control_files)\n",
        "\n",
        "print(f\"Found {len(parkinson_files)} Parkinson files and {len(control_files)} Control files.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VboBLoTI-Rlj"
      },
      "source": [
        "# Load ParkCeleb dataset and extract speaker IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_I5raZBx-R2X"
      },
      "outputs": [],
      "source": [
        "def load_parkceleb_dataset_with_speakers(dataset_path):\n",
        "    groups = {\"PD\": 1, \"CN\": 0}\n",
        "    audio_files = []\n",
        "    labels = []\n",
        "    speaker_ids = []\n",
        "\n",
        "    # Loop over each group (PD, CN)\n",
        "    for group, label in groups.items():\n",
        "        group_path = os.path.join(dataset_path, group)\n",
        "        # Recursively search for the specific file\n",
        "        for audio_file in glob(os.path.join(group_path, \"**\", \"*.wav\"), recursive=True):\n",
        "            audio_files.append(audio_file)\n",
        "            labels.append(label)\n",
        "\n",
        "            # Extract speaker ID from the path (assuming structure where speaker ID is the directory name after the group name e.g. CN/cn_01 or PD/pd_01)\n",
        "            try:\n",
        "                # Example: dataset_path/PD/speaker01/utterance_1.wav\n",
        "                relative_path = os.path.relpath(audio_file, group_path)\n",
        "                speaker_id = relative_path.split(os.sep)[0]\n",
        "                speaker_ids.append(speaker_id)\n",
        "            except IndexError:\n",
        "                print(f\"Could not extract speaker ID from path: {audio_file}\")\n",
        "                speaker_ids.append(None) # Handle cases where speaker ID cannot be extracted, caused by errors in dataset\n",
        "\n",
        "    # Filter out files where speaker ID couldn't be determined, some stupid bug\n",
        "    valid_indices = [i for i, spkr_id in enumerate(speaker_ids) if spkr_id is not None]\n",
        "    audio_files = [audio_files[i] for i in valid_indices]\n",
        "    labels = [labels[i] for i in valid_indices]\n",
        "    speaker_ids = [speaker_ids[i] for i in valid_indices]\n",
        "\n",
        "    return audio_files, labels, speaker_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFbQrRZpC35N"
      },
      "source": [
        "# Create whisper features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSj1VZpWC4E4"
      },
      "outputs": [],
      "source": [
        "# Read time before diagnosis from speakers_info.csv\n",
        "def get_time_before_diagnosis(speaker_path):\n",
        "    info_path = os.path.join(speaker_path, \"speakers_info.csv\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(info_path)\n",
        "        # Filter rows based on conditions\n",
        "        filtered = df[\n",
        "            (df['status'] == 'target') &\n",
        "            (df['before_after_diagnosis'] == 'before') &\n",
        "            (df['years_from_diagnosis'].between(0, 11, inclusive='neither'))\n",
        "        ]\n",
        "        if not filtered.empty:\n",
        "            return filtered['years_from_diagnosis'].iloc[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {info_path}: {e}\")\n",
        "    return None\n",
        "\n",
        "def extract_whisper_features(audio_paths, model_name=\"openai/whisper-small\"):\n",
        "    model = WhisperModel.from_pretrained(model_name)\n",
        "    feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "    ids = []\n",
        "    times = []\n",
        "    lengths = []\n",
        "    successful_paths = []\n",
        "\n",
        "    for audio_path in tqdm(audio_paths, desc=\"Extracting Whisper features\"):\n",
        "        try:\n",
        "            audio_array, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
        "            # print(audio_path)\n",
        "\n",
        "            # Extract features using the feature extractor\n",
        "            inputs = feature_extractor(\n",
        "                audio_array,\n",
        "                sampling_rate=16000,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            # Define a decoder input for Whisper (needed for the forward pass structure)\n",
        "            # This is not really used, but whisper requires it to be passed, regardless if you do or do not use the decoder.\n",
        "            decoder_input_ids = torch.tensor([[1] * 100]).to(device) # Add 100 tokens for the decoder input\n",
        "\n",
        "            # Move inputs to the correct device\n",
        "            inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "            # Forward pass to get hidden states\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs, decoder_input_ids=decoder_input_ids, output_hidden_states=True)\n",
        "\n",
        "            # Get the last hidden state from the encoder and average across the sequence dimension\n",
        "            embeddings = outputs.encoder_hidden_states[-1].mean(dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "\n",
        "            # get patient id (pd_01 etc)\n",
        "            patient_id = Path(audio_path).parts[2]\n",
        "\n",
        "            # Get time before diagnosis\n",
        "            speaker_dir = Path(audio_path).parent\n",
        "            audio_dir = Path(speaker_dir).parent\n",
        "            time_before_diagnosis = get_time_before_diagnosis(audio_dir)\n",
        "\n",
        "            group = Path(audio_path).parent.parent.name  # Parent directory of speaker dir\n",
        "            label = 1 if group == \"PD\" else 0  # Directly use group name\n",
        "\n",
        "            features.append(embeddings)\n",
        "            successful_paths.append(audio_path)\n",
        "            labels.append(label)  # Use corrected label\n",
        "            ids.append(patient_id)\n",
        "            times.append(time_before_diagnosis)\n",
        "            lengths.append(librosa.get_duration(y=audio_array, sr=sr))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {audio_path}: {e}\")\n",
        "\n",
        "    if not features:\n",
        "        return np.array([]), [] # Return empty arrays if no features were extracted\n",
        "\n",
        "    return np.array(features), list(labels), list(ids), list(times), list(lengths), successful_paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2jtUkdCGn00"
      },
      "source": [
        "# Extract traditional features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuxIJIbsGm8t"
      },
      "outputs": [],
      "source": [
        "def extract_traditional_features(audio_paths):\n",
        "    features = []\n",
        "    labels = []\n",
        "    ids = []\n",
        "    times = []\n",
        "    lengths = []\n",
        "    successful_paths = []\n",
        "\n",
        "    for audio_path in tqdm(audio_paths, desc=\"Extracting traditional features\"):\n",
        "        try:\n",
        "            # Load audio ONCE with librosa\n",
        "            audio_array, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "            patient_id = Path(audio_path).parts[2]\n",
        "            speaker_dir = Path(audio_path).parent\n",
        "            audio_dir = Path(speaker_dir).parent\n",
        "            time_before_diagnosis = get_time_before_diagnosis(audio_dir)\n",
        "            duration = librosa.get_duration(y=audio_array, sr=sr)\n",
        "            group = Path(audio_path).parent.parent.name\n",
        "            label = 1 if group == \"PD\" else 0\n",
        "\n",
        "            # Create parselmouth Sound object from librosa's data\n",
        "            try:\n",
        "                # Ensure 'audio_array' is float64 for parselmouth, librosa might return float32\n",
        "                sound = parselmouth.Sound(audio_array.astype(np.float64), sampling_frequency=sr)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to create parselmouth.Sound from array for {audio_path}: {e}\")\n",
        "                # Skip this file if parselmouth object creation fails\n",
        "                continue\n",
        "\n",
        "            feature_vector = []\n",
        "\n",
        "            # Jitter features\n",
        "            try:\n",
        "                pointProcess = call(sound, \"To PointProcess (periodic, cc)\", 75, 600)\n",
        "                jitter_local = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "                jitter_local_absolute = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "                jitter_rap = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "                jitter_ppq5 = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
        "                feature_vector.extend([jitter_local, jitter_local_absolute, jitter_rap, jitter_ppq5])\n",
        "            except Exception as e:\n",
        "                feature_vector.extend([0, 0, 0, 0])\n",
        "\n",
        "            # Shimmer features\n",
        "            try:\n",
        "                shimmer_local = call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "                shimmer_local_db = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
        "                feature_vector.extend([shimmer_local, shimmer_local_db])\n",
        "            except Exception as e:\n",
        "                feature_vector.extend([0, 0])\n",
        "\n",
        "            # Harmonics-to-noise ratio\n",
        "            try:\n",
        "                harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
        "                hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
        "                feature_vector.append(hnr)\n",
        "            except Exception as e:\n",
        "                feature_vector.append(0)\n",
        "\n",
        "            # Percentage of vocalic intervals (using RMS energy)\n",
        "            rms_frames = librosa.feature.rms(y=audio_array).mean()\n",
        "            feature_vector.append(rms_frames)\n",
        "\n",
        "            # MFCCs\n",
        "            try:\n",
        "                mfccs = librosa.feature.mfcc(y=audio_array, sr=sr, n_mfcc=13)\n",
        "                mfcc_means = np.mean(mfccs, axis=1)\n",
        "                feature_vector.extend(mfcc_means)\n",
        "            except Exception as e:\n",
        "                feature_vector.extend([0] * 13)\n",
        "\n",
        "            # Spectral features\n",
        "            try:\n",
        "                spectral_centroid = librosa.feature.spectral_centroid(y=audio_array, sr=sr).mean()\n",
        "                spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_array, sr=sr).mean()\n",
        "                feature_vector.extend([spectral_centroid, spectral_bandwidth])\n",
        "            except Exception as e:\n",
        "                feature_vector.extend([0, 0])\n",
        "\n",
        "            # F0 Statistics (Prosodic Features)\n",
        "            f0_values = []\n",
        "            try:\n",
        "                pitch = sound.to_pitch()\n",
        "                f0_values = pitch.selected_array['frequency']\n",
        "                f0_values = f0_values[f0_values != 0] # Exclude unvoiced frames (0 Hz)\n",
        "                if len(f0_values) > 0:\n",
        "                    f0_mean = np.mean(f0_values)\n",
        "                    f0_std = np.std(f0_values)\n",
        "                    f0_range = np.max(f0_values) - np.min(f0_values)\n",
        "                else:\n",
        "                    f0_mean, f0_std, f0_range = 0, 0, 0 # Handle case with no voiced frames\n",
        "\n",
        "                feature_vector.extend([f0_mean, f0_std, f0_range])\n",
        "            except Exception as e:\n",
        "                feature_vector.extend([0, 0, 0])\n",
        "\n",
        "            # Nonlinear Dynamics (RPDE, D2, DFA)\n",
        "            rpde_val, d2_val, dfa_val = 0, 0, 0 # Default to 0 if not computed\n",
        "\n",
        "            if len(f0_values) > 10: # Need enough points for nolds functions\n",
        "                try:\n",
        "                    # These can be computationally expensive, consider skipping for large files\n",
        "                    if len(f0_values) < 5000:  # Limit to prevent memory issues\n",
        "                        rpde_val = nolds.rpde(f0_values)\n",
        "                        d2_val = nolds.d2(f0_values)\n",
        "                        dfa_val = nolds.dfa(f0_values)\n",
        "                except Exception as e:\n",
        "                    pass # Keep default 0 values\n",
        "\n",
        "            feature_vector.extend([rpde_val, d2_val, dfa_val])\n",
        "\n",
        "            # Check if feature vector has consistent length\n",
        "            expected_length = 29 # Update if adding/removing features\n",
        "            if len(feature_vector) == expected_length:\n",
        "                features.append(feature_vector)\n",
        "                labels.append(label)\n",
        "                ids.append(patient_id)\n",
        "                times.append(time_before_diagnosis)\n",
        "                lengths.append(duration)  # Using duration instead of audio_length\n",
        "                successful_paths.append(audio_path)\n",
        "            else:\n",
        "                print(f\"Skipping {audio_path} due to inconsistent feature vector length ({len(feature_vector)} != {expected_length})\")\n",
        "\n",
        "            # Force garbage collection to free memory\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred processing file: {audio_path}. Error: {e}\")\n",
        "\n",
        "    features_array = np.array(features, dtype=np.float32)\n",
        "    return features_array, labels, ids, times, lengths, successful_paths  # Return all data, not just features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cllmJlq4ITS-"
      },
      "source": [
        "# Loading CSV helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-2OzAVgITsK"
      },
      "outputs": [],
      "source": [
        "# New function to load features from CSV\n",
        "def load_features_from_csv(filename):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"File not found: {filename}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    print(f\"Loading features from: {filename}\")\n",
        "    df = pd.read_csv(filename)\n",
        "    required_columns = {'label', 'id', 'time_before_diagnosis', 'length'}\n",
        "    if not required_columns.issubset(df.columns):\n",
        "        print(f\"Error: One or more required columns {required_columns} missing in {filename}\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    labels = df['label'].values.astype(int)\n",
        "    speaker_ids = df['id'].values\n",
        "    times = df['time_before_diagnosis'].values\n",
        "    lengths = df['length'].values\n",
        "\n",
        "    features = df.drop(columns=['label', 'id', 'time_before_diagnosis', 'length']).values.astype(np.float32)\n",
        "    features = np.nan_to_num(features)\n",
        "\n",
        "    return features, labels, speaker_ids, times, lengths, df\n",
        "\n",
        "\n",
        "\n",
        "# Save features function\n",
        "def save_features(features, labels, ids, time_before_diagnosis, audio_length, filename):\n",
        "    \"\"\"Save features and labels to a CSV file.\"\"\"\n",
        "    if features.size == 0 or not labels:\n",
        "        print(f\"Warning: No features or labels to save for {filename}\")\n",
        "        return\n",
        "    df = pd.DataFrame(features)\n",
        "    df['label'] = labels\n",
        "    df['id'] = ids\n",
        "    df['time_before_diagnosis'] = time_before_diagnosis\n",
        "    df['length'] = audio_length\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Saved features to {filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxwzcv0hIXU1"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DznagIoBIYoQ"
      },
      "outputs": [],
      "source": [
        "class DeepNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(DeepNN, self).__init__()\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_dim, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.3),\n",
        "            torch.nn.Linear(256, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.3),\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64, 1),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class ImprovedDeepNN(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes=1, dropout=0.3):\n",
        "        super(ImprovedDeepNN, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.bn4 = nn.BatchNorm1d(64)\n",
        "\n",
        "        self.output = nn.Linear(64, num_classes)  # 1 for binary, >1 for multi-class (depends on number of bins)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc4(x)))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        if self.num_classes == 1:\n",
        "            return torch.sigmoid(self.output(x))  # Binary classification\n",
        "        else:\n",
        "            return self.output(x)  # Use CrossEntropyLoss with raw logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83TD4k9YaXrv"
      },
      "source": [
        "# Model Training/Testing/Comparison Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATb3Un62aX7p"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred_prob):\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"roc_auc\": roc_auc_score(y_true, y_pred_prob) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "        \"sensitivity\": recall_score(y_true, y_pred),\n",
        "        \"specificity\": recall_score(1 - y_true, 1 - y_pred),\n",
        "        \"f1_score\": f1_score(y_true, y_pred),\n",
        "        \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "def calculate_comprehensive_statistics(results_list):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive statistics for cross-validation results.\n",
        "\n",
        "    Returns statistics including:\n",
        "    - Mean and standard deviation\n",
        "    - Variance and coefficient of variation\n",
        "    - 95% confidence intervals\n",
        "    - Min/max values\n",
        "    - Statistical significance tests\n",
        "    \"\"\"\n",
        "    if not results_list or len(results_list) == 0:\n",
        "        return {}\n",
        "\n",
        "    stats_dict = {}\n",
        "    metric_keys = [key for key in results_list[0].keys() if key != 'confusion_matrix']\n",
        "\n",
        "    for key in metric_keys:\n",
        "        values = [res[key] for res in results_list if not np.isnan(res[key])]\n",
        "\n",
        "        if len(values) == 0:\n",
        "            stats_dict[key] = {\n",
        "                'mean': np.nan, 'std': np.nan, 'variance': np.nan,\n",
        "                'cv': np.nan, 'ci_lower': np.nan, 'ci_upper': np.nan,\n",
        "                'min': np.nan, 'max': np.nan, 'range': np.nan,\n",
        "                'median': np.nan, 'iqr': np.nan, 'n_valid': 0\n",
        "            }\n",
        "            continue\n",
        "\n",
        "        values = np.array(values)\n",
        "        n = len(values)\n",
        "        mean_val = np.mean(values)\n",
        "        std_val = np.std(values, ddof=1) if n > 1 else 0\n",
        "\n",
        "        # Basic statistics\n",
        "        stats_dict[key] = {\n",
        "            'mean': mean_val,\n",
        "            'std': std_val,\n",
        "            'variance': np.var(values, ddof=1) if n > 1 else 0,\n",
        "            'cv': (std_val / mean_val * 100) if mean_val != 0 else np.nan,  # Coefficient of variation as percentage\n",
        "            'min': np.min(values),\n",
        "            'max': np.max(values),\n",
        "            'range': np.max(values) - np.min(values),\n",
        "            'median': np.median(values),\n",
        "            'iqr': np.percentile(values, 75) - np.percentile(values, 25),\n",
        "            'n_valid': n\n",
        "        }\n",
        "\n",
        "        # 95% Confidence interval for the mean\n",
        "        if n > 1:\n",
        "            ci = stats.t.interval(0.95, n-1, loc=mean_val, scale=stats.sem(values))\n",
        "            stats_dict[key]['ci_lower'] = ci[0]\n",
        "            stats_dict[key]['ci_upper'] = ci[1]\n",
        "        else:\n",
        "            stats_dict[key]['ci_lower'] = mean_val\n",
        "            stats_dict[key]['ci_upper'] = mean_val\n",
        "\n",
        "    return stats_dict\n",
        "\n",
        "def print_comprehensive_statistics(feature_type, stats_dict):\n",
        "    \"\"\"Print detailed statistics in a formatted way\"\"\"\n",
        "    print(f\"\\n=== {feature_type} Features - Comprehensive Statistics ===\")\n",
        "\n",
        "    # Define the metrics we want to display\n",
        "    metric_display_names = {\n",
        "        'accuracy': 'Accuracy',\n",
        "        'roc_auc': 'ROC AUC',\n",
        "        'sensitivity': 'Sensitivity (Recall)',\n",
        "        'specificity': 'Specificity',\n",
        "        'f1_score': 'F1 Score'\n",
        "    }\n",
        "\n",
        "    for metric, display_name in metric_display_names.items():\n",
        "        if metric in stats_dict:\n",
        "            s = stats_dict[metric]\n",
        "            print(f\"\\n{display_name}:\")\n",
        "            print(f\"  Mean ± SD:        {s['mean']:.4f} ± {s['std']:.4f}\")\n",
        "            print(f\"  95% CI:           [{s['ci_lower']:.4f}, {s['ci_upper']:.4f}]\")\n",
        "            print(f\"  Variance:         {s['variance']:.6f}\")\n",
        "            print(f\"  CV:               {s['cv']:.2f}%\")  # Coefficient of variation\n",
        "            print(f\"  Range:            [{s['min']:.4f}, {s['max']:.4f}] (span: {s['range']:.4f})\")\n",
        "            print(f\"  Median (IQR):     {s['median']:.4f} ({s['iqr']:.4f})\")\n",
        "\n",
        "def create_visualizations(feature_types, all_fold_metrics, all_stats, save_folder, save_figures):\n",
        "    \"\"\"Create visualizations with error bars and confidence intervals\"\"\"\n",
        "\n",
        "    metric_names = ['Accuracy', 'AUC', 'Sensitivity', 'Specificity', 'F1 Score']\n",
        "    metric_keys = ['accuracy', 'roc_auc', 'sensitivity', 'specificity', 'f1_score']\n",
        "\n",
        "    if len(feature_types) > 1:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Main comparison with error bars\n",
        "        width = 0.35\n",
        "        x = np.arange(len(metric_names))\n",
        "\n",
        "        for i, feature_type in enumerate(feature_types):\n",
        "            means = [all_stats[feature_type][key]['mean'] for key in metric_keys]\n",
        "            stds = [all_stats[feature_type][key]['std'] for key in metric_keys]\n",
        "\n",
        "            bars = ax1.bar(x + (i - 0.5*(len(feature_types)-1)) * width, means,\n",
        "                          width, label=feature_type, alpha=0.8,\n",
        "                          yerr=stds, capsize=5, error_kw=dict(alpha=0.6))\n",
        "\n",
        "            # Add value labels with mean ± std\n",
        "            for j, (mean, std) in enumerate(zip(means, stds)):\n",
        "                ax1.text(x[j] + (i - 0.5*(len(feature_types)-1)) * width,\n",
        "                        mean + std + 0.02,\n",
        "                        f'{mean:.3f}±{std:.3f}',\n",
        "                        ha='center', fontsize=8, rotation=0)\n",
        "\n",
        "        ax1.axhline(y=0.5, color='r', linestyle='--', alpha=0.3, label='Baseline')\n",
        "        ax1.set_xlabel('Metric')\n",
        "        ax1.set_ylabel('Score')\n",
        "        ax1.set_title('Performance Comparison with Standard Deviation')\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(metric_names)\n",
        "        ax1.set_ylim(0, 1.1)\n",
        "        ax1.legend()\n",
        "        ax1.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "        # Coefficient of variation comparison\n",
        "        cvs_data = []\n",
        "        for feature_type in feature_types:\n",
        "            cvs = [all_stats[feature_type][key]['cv'] for key in metric_keys]\n",
        "            cvs_data.append(cvs)\n",
        "\n",
        "        x_cv = np.arange(len(metric_names))\n",
        "        for i, (feature_type, cvs) in enumerate(zip(feature_types, cvs_data)):\n",
        "            ax2.bar(x_cv + (i - 0.5*(len(feature_types)-1)) * width, cvs,\n",
        "                   width, label=feature_type, alpha=0.8)\n",
        "\n",
        "            # Add value labels\n",
        "            for j, cv in enumerate(cvs):\n",
        "                if not np.isnan(cv):\n",
        "                    ax2.text(x_cv[j] + (i - 0.5*(len(feature_types)-1)) * width,\n",
        "                            cv + 0.5, f'{cv:.1f}%',\n",
        "                            ha='center', fontsize=8)\n",
        "\n",
        "        ax2.set_xlabel('Metric')\n",
        "        ax2.set_ylabel('Coefficient of Variation (%)')\n",
        "        ax2.set_title('Model Stability (Lower CV = More Stable)')\n",
        "        ax2.set_xticks(x_cv)\n",
        "        ax2.set_xticklabels(metric_names)\n",
        "        ax2.legend()\n",
        "        ax2.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save_figures:\n",
        "            plt.savefig(f'{save_folder}/feature_comparison.png',\n",
        "                       bbox_inches='tight', dpi=300)\n",
        "            plt.close()\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "    # Box plots for each feature type showing distribution across folds\n",
        "    for feature_type in feature_types:\n",
        "        if feature_type not in all_fold_metrics:\n",
        "            continue\n",
        "\n",
        "        fold_data = all_fold_metrics[feature_type]\n",
        "\n",
        "        # Create box plot data\n",
        "        box_data = []\n",
        "        box_labels = []\n",
        "        for key, display_name in zip(metric_keys, metric_names):\n",
        "            if key in fold_data and len(fold_data[key]) > 0:\n",
        "                box_data.append(fold_data[key])\n",
        "                box_labels.append(display_name)\n",
        "\n",
        "        if box_data:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            bp = plt.boxplot(box_data, labels=box_labels, patch_artist=True)\n",
        "\n",
        "            # Color the boxes\n",
        "            colors = plt.cm.Set3(np.linspace(0, 1, len(box_data)))\n",
        "            for patch, color in zip(bp['boxes'], colors):\n",
        "                patch.set_facecolor(color)\n",
        "                patch.set_alpha(0.7)\n",
        "\n",
        "            plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.3, label='Baseline')\n",
        "            plt.ylabel('Score')\n",
        "            plt.title(f'{feature_type} - Distribution of Metrics Across Folds')\n",
        "            plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "            plt.ylim(0, 1.05)\n",
        "\n",
        "            # Add mean markers\n",
        "            for i, key in enumerate([k for k in metric_keys if k in fold_data]):\n",
        "                if len(fold_data[key]) > 0:\n",
        "                    mean_val = np.mean(fold_data[key])\n",
        "                    plt.scatter(i+1, mean_val, color='red', s=50, marker='D',\n",
        "                              label='Mean' if i == 0 else '', zorder=5)\n",
        "\n",
        "            plt.legend()\n",
        "            plt.xticks(rotation=45)\n",
        "\n",
        "            if save_figures:\n",
        "                plt.savefig(f'{save_folder}/{feature_type}_distribution_boxplot.png',\n",
        "                           bbox_inches='tight', dpi=300)\n",
        "                plt.close()\n",
        "            else:\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "def average_metrics(results_list):\n",
        "    \"\"\"Backward compatibility - returns means only\"\"\"\n",
        "    return {\n",
        "        key: np.nanmean([res[key] for res in results_list])\n",
        "        for key in results_list[0].keys()\n",
        "    }\n",
        "\n",
        "def empty_metrics():\n",
        "    return {\n",
        "        \"accuracy\": np.nan,\n",
        "        \"roc_auc\": np.nan,\n",
        "        \"sensitivity\": np.nan,\n",
        "        \"specificity\": np.nan,\n",
        "        \"f1_score\": np.nan,\n",
        "        \"confusion_matrix\": np.array([[0, 0], [0, 0]])\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pZtXFUrIh9O"
      },
      "source": [
        "# Training, Testing, and Saving DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kmd_vs_IiQL"
      },
      "outputs": [],
      "source": [
        "def get_model_save_path(base_folder, feature_type, deep_features, model_name, fold, model_to_use):\n",
        "    \"\"\"Generate the path for saving/loading models\"\"\"\n",
        "    # Create folder structure: models/{deep_features}/{feature_type}_{model_name}/\n",
        "    if feature_type == \"Whisper\":\n",
        "        model_folder = Path(base_folder) / \"models\" / deep_features.replace(\" \", \"_\").lower() / f\"{feature_type}_{model_name}\"\n",
        "    else:\n",
        "        model_folder = Path(base_folder) / \"models\" / \"traditional\" / f\"{feature_type}_{model_name}\"\n",
        "\n",
        "    model_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Use appropriate extension based on model type\n",
        "    if hasattr(model_to_use, '__name__') and not model_to_use.__name__.startswith('RandomForestClassifier'):\n",
        "        # Neural network models use .pth\n",
        "        return model_folder / f\"fold_{fold}.pth\"\n",
        "    else:\n",
        "        # Sklearn models use .pkl\n",
        "        return model_folder / f\"fold_{fold}.pkl\"\n",
        "\n",
        "def save_model_and_scaler(model, scaler, model_path, model_to_use):\n",
        "    \"\"\"Save model and scaler to disk\"\"\"\n",
        "    try:\n",
        "        # Handle PyTorch models separately\n",
        "        if hasattr(model, 'state_dict'):  # PyTorch model\n",
        "            # Save PyTorch model using torch.save\n",
        "            save_data = {\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'model_class': model.__class__,\n",
        "                'input_dim': getattr(model, 'input_size', None) or model.state_dict()[list(model.state_dict().keys())[0]].shape[1],\n",
        "                'scaler': scaler,\n",
        "                'model_type': model_to_use.__name__ if hasattr(model_to_use, '__name__') else str(type(model_to_use))\n",
        "            }\n",
        "            torch.save(save_data, model_path)\n",
        "\n",
        "        else:  # Sklearn model\n",
        "            save_data = {\n",
        "                'model': model,\n",
        "                'scaler': scaler,\n",
        "                'model_type': model_to_use.__name__ if hasattr(model_to_use, '__name__') else str(type(model_to_use))\n",
        "            }\n",
        "            joblib.dump(save_data, model_path)\n",
        "\n",
        "        print(f\"Model saved to: {model_path}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model to {model_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_model_and_scaler(model_path, model_to_use, input_dim=None):\n",
        "    \"\"\"Load model and scaler from disk\"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(model_path):\n",
        "            return None, None\n",
        "\n",
        "        # Handle PyTorch models (.pth files)\n",
        "        if str(model_path).endswith('.pth'):\n",
        "            save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            scaler = save_data['scaler']\n",
        "\n",
        "            if input_dim is None:\n",
        "                input_dim = save_data.get('input_dim')\n",
        "            if input_dim is None:\n",
        "                raise ValueError(\"input_dim required for PyTorch model loading\")\n",
        "\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model = model_to_use(input_dim).to(device)\n",
        "            model.load_state_dict(save_data['model_state_dict'])\n",
        "            model.eval()\n",
        "\n",
        "        else:  # Sklearn models (.pkl files)\n",
        "            save_data = joblib.load(model_path)\n",
        "            model = save_data['model']\n",
        "            scaler = save_data['scaler']\n",
        "\n",
        "        print(f\"Model loaded from: {model_path}\")\n",
        "        return model, scaler\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from {model_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def train_evaluate_model(X_train, y_train, X_test, y_test, feature_type, model_to_use,\n",
        "                        model_save_path=None, force_retrain=False):\n",
        "    \"\"\"Train and evaluate model for specific feature type with save/load functionality\"\"\"\n",
        "    if X_train.size == 0 or X_test.size == 0:\n",
        "        print(f\"Warning: Empty feature sets for {feature_type}. Skipping evaluation.\")\n",
        "        return empty_metrics()\n",
        "\n",
        "    # Try to load existing model if save path is provided and force_retrain is False\n",
        "    model, scaler = None, None\n",
        "    if model_save_path and not force_retrain:\n",
        "        model, scaler = load_model_and_scaler(model_save_path, model_to_use, X_train.shape[1])\n",
        "\n",
        "    # If model not loaded, train a new one\n",
        "    if model is None or scaler is None:\n",
        "        print(f\"Training new model for {feature_type}...\")\n",
        "\n",
        "        # Standardize features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # For neural network models\n",
        "        if not model_to_use.__name__.startswith('RandomForestClassifier'):\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "            # Create model with appropriate input dimensions\n",
        "            input_dim = X_train_scaled.shape[1]\n",
        "            model = model_to_use(input_dim).to(device)\n",
        "\n",
        "            # Rest of training logic\n",
        "            criterion = torch.nn.BCELoss()\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "            # Convert data to tensors\n",
        "            X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
        "            y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1).to(device)\n",
        "\n",
        "            # Training loop\n",
        "            dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "            dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n",
        "\n",
        "            for epoch in range(100):\n",
        "                model.train()\n",
        "                for batch_X, batch_y in dataloader:\n",
        "                    outputs = model(batch_X)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "        # For Random Forest\n",
        "        elif model_to_use.__name__ == 'RandomForestClassifier':\n",
        "            # Create and train the random forest model\n",
        "            model = model_to_use(\n",
        "                n_estimators=100,\n",
        "                max_depth=None,\n",
        "                min_samples_split=2,\n",
        "                min_samples_leaf=1,\n",
        "                max_features='sqrt',\n",
        "                bootstrap=True,\n",
        "                random_state=37,\n",
        "                n_jobs=-1,\n",
        "                class_weight='balanced'\n",
        "            )\n",
        "\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # For other sklearn models\n",
        "        else:\n",
        "            model = model_to_use()\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Save the trained model and scaler\n",
        "        if model_save_path:\n",
        "            save_model_and_scaler(model, scaler, model_save_path, model_to_use)\n",
        "\n",
        "    else:\n",
        "        print(f\"Using loaded model for {feature_type}...\")\n",
        "        # Use the loaded scaler to transform test data\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Evaluation (same for both loaded and newly trained models)\n",
        "    if not model_to_use.__name__.startswith('RandomForestClassifier'):\n",
        "        # Neural network evaluation\n",
        "        model.eval()\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_pred_prob = model(X_test_tensor).cpu().numpy()\n",
        "    else:\n",
        "        # Sklearn model evaluation\n",
        "        y_pred_prob = model.predict_proba(X_test_scaled)[:, 1].reshape(-1, 1)\n",
        "\n",
        "    return calculate_metrics(y_test, y_pred_prob)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhMR2mh_Ixx8"
      },
      "source": [
        "# Train model + Feature comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BywVXbGnGpTb"
      },
      "outputs": [],
      "source": [
        "def crossval_compare_features(dataset_path, k=5, save_figures=True, min_audio_length=0,\n",
        "                            deep_features=\"Whisper Small\", model=None, force_retrain=False,\n",
        "                            base_save_folder='experiment_results'):\n",
        "    # Determine which model to use\n",
        "    if model == \"random_forest\":\n",
        "        model_to_use = RandomForestClassifier\n",
        "        model_name = \"RandomForest\"\n",
        "    elif isinstance(model, type) or callable(model):\n",
        "        # If model is a class or function\n",
        "        model_to_use = model\n",
        "        model_name = model.__name__\n",
        "    else:\n",
        "        # If model is an instance\n",
        "        model_to_use = model\n",
        "        model_name = model.__class__.__name__\n",
        "\n",
        "    save_folder = f'{base_save_folder}/{deep_features}/visualization_results_{model_name}'\n",
        "    # Create directory for saving figures if needed\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "    # Load data with proper alignment\n",
        "    all_audio_paths, all_labels, all_speaker_ids = load_parkceleb_dataset_with_speakers(dataset_path)\n",
        "\n",
        "    # Load features\n",
        "    if deep_features == \"Whisper Small\":\n",
        "        whisper_data = load_features_from_csv(\"whisper_small_all_features.csv\")\n",
        "        traditional_data = load_features_from_csv(\"traditional_all_features.csv\")\n",
        "    elif deep_features == \"Whisper Medium\":\n",
        "        whisper_data = load_features_from_csv(\"whisper_medium_all_features.csv\")\n",
        "        traditional_data = load_features_from_csv(\"traditional_all_features.csv\")\n",
        "\n",
        "    if whisper_data[0] is None:\n",
        "        print(\"Whisper data is None. Generating features.\")\n",
        "        features, labels, ids, times, lengths, _ = extract_whisper_features(all_audio_paths)\n",
        "        # Change CSV names according to whisper model used\n",
        "        save_features(features, labels, ids, times, lengths, \"whisper_medium_all_features.csv\")\n",
        "        whisper_data = load_features_from_csv(\"whisper_medium_all_features.csv\")\n",
        "\n",
        "    if traditional_data[0] is None:\n",
        "        print(\"Traditional data is None. Generating features.\")\n",
        "        features, labels, ids, times, lengths, _ = extract_traditional_features(all_audio_paths)\n",
        "        save_features(features, labels, ids, times, lengths, \"traditional_all_features.csv\")\n",
        "        traditional_data = load_features_from_csv(\"traditional_all_features.csv\")\n",
        "\n",
        "    # Dictionary to store all results\n",
        "    results = {}\n",
        "    all_fold_metrics = {}  # Store metrics for each fold for later visualization\n",
        "    all_comprehensive_stats = {}  # Store comprehensive statistics\n",
        "\n",
        "    for feature_type, (features, labels, speakers, times, lengths, _) in [\n",
        "        (\"Whisper\", whisper_data),\n",
        "        (\"Traditional\", traditional_data)\n",
        "    ]:\n",
        "        if features is None:\n",
        "            continue\n",
        "\n",
        "        length_mask = lengths >= min_audio_length\n",
        "        features = features[length_mask]\n",
        "        labels = labels[length_mask]\n",
        "        speakers = speakers[length_mask]\n",
        "        times = times[length_mask]\n",
        "        lengths = lengths[length_mask]\n",
        "\n",
        "        print(f\"\\n=== Processing {feature_type} Features with {model_name} ===\")\n",
        "        print(f\"Feature dimension: {features.shape[1]}\")\n",
        "        print(f\"Class distribution: {np.bincount(labels)}\")\n",
        "\n",
        "        # Speaker-level stratified K-Fold\n",
        "        unique_speakers = np.unique(speakers)\n",
        "        speaker_labels = np.array([1 if 'pd' in s else 0 for s in unique_speakers])\n",
        "\n",
        "        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=37)\n",
        "        fold_results = []\n",
        "        fold_metrics_dict = {\n",
        "            'accuracy': [], 'roc_auc': [], 'sensitivity': [],\n",
        "            'specificity': [], 'f1_score': [], 'confusion_matrices': [],\n",
        "            'y_test': [], 'y_pred_prob': [], 'feature_importance': []\n",
        "        }\n",
        "\n",
        "        for fold, (train_idx, test_idx) in enumerate(skf.split(unique_speakers, speaker_labels)):\n",
        "            print(f\"\\n=== Fold {fold+1} ===\")\n",
        "            train_speakers = set(unique_speakers[train_idx])\n",
        "            test_speakers = set(unique_speakers[test_idx])\n",
        "\n",
        "            # Select data for current fold\n",
        "            train_mask = np.isin(speakers, list(train_speakers))\n",
        "            test_mask = np.isin(speakers, list(test_speakers))\n",
        "\n",
        "            X_train, X_test = features[train_mask], features[test_mask]\n",
        "            y_train, y_test = labels[train_mask], labels[test_mask]\n",
        "\n",
        "            # Check for valid class distribution\n",
        "            if len(np.unique(y_test)) < 2:\n",
        "                print(f\"Skipping fold {fold+1} - single class in test set\")\n",
        "                continue\n",
        "\n",
        "            # Get model save path for this fold\n",
        "            model_save_path = get_model_save_path(base_save_folder, feature_type, deep_features, model_name, fold+1, model_to_use)\n",
        "\n",
        "            # Train and Eval\n",
        "            metrics = train_evaluate_model(X_train, y_train, X_test, y_test, feature_type,\n",
        "                                         model_to_use, model_save_path, force_retrain)\n",
        "            fold_results.append(metrics)\n",
        "\n",
        "            # Store detailed metrics for visualization\n",
        "            for key in ['accuracy', 'roc_auc', 'sensitivity', 'specificity', 'f1_score']:\n",
        "                fold_metrics_dict[key].append(metrics[key])\n",
        "            fold_metrics_dict['confusion_matrices'].append(metrics['confusion_matrix'])\n",
        "            fold_metrics_dict['y_test'].append(y_test)\n",
        "\n",
        "            # Visualize confusion matrix for this fold\n",
        "            plt.figure(figsize=(6, 5))\n",
        "            cm = metrics['confusion_matrix']\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                        xticklabels=['Control', 'PD'], yticklabels=['Control', 'PD'])\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.title(f'{feature_type} - Fold {fold+1} Confusion Matrix')\n",
        "            if save_figures:\n",
        "                plt.savefig(f'{save_folder}/{feature_type}_fold{fold+1}_confusion.png', bbox_inches='tight')\n",
        "                plt.close()\n",
        "            else:\n",
        "                plt.show()\n",
        "\n",
        "        # Store results\n",
        "        if fold_results:\n",
        "            results[feature_type] = average_metrics(fold_results)\n",
        "            all_fold_metrics[feature_type] = fold_metrics_dict\n",
        "\n",
        "            # Calculate comprehensive statistics\n",
        "            comprehensive_stats = calculate_comprehensive_statistics(fold_results)\n",
        "            all_comprehensive_stats[feature_type] = comprehensive_stats\n",
        "\n",
        "            # Print comprehensive statistics\n",
        "            print_comprehensive_statistics(feature_type, comprehensive_stats)\n",
        "\n",
        "            # Visualize metrics across folds with error bars\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            metrics_across_folds = pd.DataFrame({\n",
        "                'Accuracy': fold_metrics_dict['accuracy'],\n",
        "                'AUC': fold_metrics_dict['roc_auc'],\n",
        "                'Sensitivity': fold_metrics_dict['sensitivity'],\n",
        "                'Specificity': fold_metrics_dict['specificity'],\n",
        "                'F1 Score': fold_metrics_dict['f1_score']\n",
        "            })\n",
        "\n",
        "            metrics_across_folds.index = [f'Fold {i+1}' for i in range(len(metrics_across_folds))]\n",
        "            ax = metrics_across_folds.plot(kind='bar', figsize=(12, 6))\n",
        "\n",
        "            # Add error bars showing standard deviation\n",
        "            means = metrics_across_folds.mean()\n",
        "            stds = metrics_across_folds.std()\n",
        "\n",
        "            plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.3)  # baseline\n",
        "            plt.title(f'{feature_type} - Performance Metrics Across Folds\\n'\n",
        "                     f'Mean ± SD shown in legend')\n",
        "            plt.ylabel('Score')\n",
        "            plt.ylim(0, 1.05)\n",
        "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "            # Update legend to include mean ± std\n",
        "            handles, labels = ax.get_legend_handles_labels()\n",
        "            new_labels = [f'{label}: {means[label]:.3f}±{stds[label]:.3f}'\n",
        "                         for label in labels]\n",
        "            plt.legend(handles, new_labels, loc='lower center',\n",
        "                      bbox_to_anchor=(0.5, -0.35), ncol=3)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for container in ax.containers:\n",
        "                ax.bar_label(container, fmt='%.3f', fontsize=7)\n",
        "\n",
        "            if save_figures:\n",
        "                plt.savefig(f'{save_folder}/{feature_type}_metrics_by_fold.png',\n",
        "                           bbox_inches='tight', dpi=300)\n",
        "                plt.close()\n",
        "            else:\n",
        "                plt.show()\n",
        "\n",
        "            # Visualize average confusion matrix\n",
        "            plt.figure(figsize=(6, 5))\n",
        "            avg_cm = np.mean([cm for cm in fold_metrics_dict['confusion_matrices']], axis=0)\n",
        "            std_cm = np.std([cm for cm in fold_metrics_dict['confusion_matrices']], axis=0)\n",
        "\n",
        "            # Create annotations with mean ± std\n",
        "            annotations = []\n",
        "            for i in range(avg_cm.shape[0]):\n",
        "                row = []\n",
        "                for j in range(avg_cm.shape[1]):\n",
        "                    row.append(f'{avg_cm[i,j]:.1f}±{std_cm[i,j]:.1f}')\n",
        "                annotations.append(row)\n",
        "\n",
        "            sns.heatmap(avg_cm, annot=annotations, fmt='', cmap='Blues',\n",
        "                        xticklabels=['Control', 'PD'], yticklabels=['Control', 'PD'])\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.title(f'{feature_type} - Average Confusion Matrix\\n(Mean ± SD)')\n",
        "            if save_figures:\n",
        "                plt.savefig(f'{save_folder}/{feature_type}_avg_confusion.png',\n",
        "                           bbox_inches='tight', dpi=300)\n",
        "                plt.close()\n",
        "            else:\n",
        "                plt.show()\n",
        "\n",
        "        else:\n",
        "            results[feature_type] = empty_metrics()\n",
        "            all_comprehensive_stats[feature_type] = {}\n",
        "\n",
        "    # Create visualizations\n",
        "    feature_types_with_data = [ft for ft in results.keys() if results[ft]['accuracy'] is not np.nan]\n",
        "    if feature_types_with_data:\n",
        "        create_visualizations(feature_types_with_data, all_fold_metrics,\n",
        "                                     all_comprehensive_stats, save_folder, save_figures)\n",
        "\n",
        "    # Print final summary with comprehensive statistics\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"COMPREHENSIVE CROSS-VALIDATION RESULTS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for feature_type in feature_types_with_data:\n",
        "        print(f\"\\n{feature_type} Features Summary:\")\n",
        "        stats = all_comprehensive_stats[feature_type]\n",
        "\n",
        "        print(\"┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\")\n",
        "        print(\"│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\")\n",
        "        print(\"├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\")\n",
        "\n",
        "        for key, display_name in [('accuracy', 'Accuracy'), ('roc_auc', 'ROC AUC'),\n",
        "                                 ('sensitivity', 'Sensitivity'), ('specificity', 'Specificity'),\n",
        "                                 ('f1_score', 'F1 Score')]:\n",
        "            if key in stats:\n",
        "                s = stats[key]\n",
        "                print(f\"│ {display_name:<11} │ {s['mean']:.3f}±{s['std']:.3f} │ \"\n",
        "                      f\"[{s['ci_lower']:.3f},{s['ci_upper']:.3f}] │ {s['cv']:6.1f}   │ \"\n",
        "                      f\"{s['range']:.3f}    │ {s['median']:.3f}    │\")\n",
        "\n",
        "        print(\"└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\")\n",
        "\n",
        "    return results, all_comprehensive_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WU1MTjz2P0rL",
        "outputId": "c9af1f20-2f8f-42ec-be6c-cd272d33e306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features from: whisper_small_all_features.csv\n",
            "Loading features from: traditional_all_features.csv\n",
            "\n",
            "=== Processing Whisper Features with DeepNN ===\n",
            "Feature dimension: 768\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_DeepNN/fold_1.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_DeepNN/fold_2.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/whisper_small/Whisper_DeepNN/fold_3.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_DeepNN/fold_4.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_DeepNN/fold_5.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Whisper Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5539 ± 0.0330\n",
            "  95% CI:           [0.5129, 0.5949]\n",
            "  Variance:         0.001091\n",
            "  CV:               5.96%\n",
            "  Range:            [0.5142, 0.6007] (span: 0.0866)\n",
            "  Median (IQR):     0.5563 (0.0328)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.5663 ± 0.0726\n",
            "  95% CI:           [0.4762, 0.6564]\n",
            "  Variance:         0.005264\n",
            "  CV:               12.81%\n",
            "  Range:            [0.4912, 0.6519] (span: 0.1607)\n",
            "  Median (IQR):     0.5819 (0.1225)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5785 ± 0.0348\n",
            "  95% CI:           [0.5353, 0.6217]\n",
            "  Variance:         0.001211\n",
            "  CV:               6.02%\n",
            "  Range:            [0.5321, 0.6185] (span: 0.0863)\n",
            "  Median (IQR):     0.5788 (0.0465)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5132 ± 0.1092\n",
            "  95% CI:           [0.3776, 0.6488]\n",
            "  Variance:         0.011928\n",
            "  CV:               21.28%\n",
            "  Range:            [0.3673, 0.6196] (span: 0.2523)\n",
            "  Median (IQR):     0.5506 (0.1656)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6138 ± 0.0266\n",
            "  95% CI:           [0.5808, 0.6468]\n",
            "  Variance:         0.000706\n",
            "  CV:               4.33%\n",
            "  Range:            [0.5868, 0.6520] (span: 0.0651)\n",
            "  Median (IQR):     0.6021 (0.0317)\n",
            "\n",
            "=== Processing Traditional Features with DeepNN ===\n",
            "Feature dimension: 29\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_1.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_2.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_3.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_4.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_5.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Traditional Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5801 ± 0.0646\n",
            "  95% CI:           [0.4998, 0.6603]\n",
            "  Variance:         0.004180\n",
            "  CV:               11.15%\n",
            "  Range:            [0.5021, 0.6750] (span: 0.1729)\n",
            "  Median (IQR):     0.5602 (0.0496)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.6088 ± 0.0711\n",
            "  95% CI:           [0.5206, 0.6971]\n",
            "  Variance:         0.005053\n",
            "  CV:               11.68%\n",
            "  Range:            [0.5502, 0.7092] (span: 0.1590)\n",
            "  Median (IQR):     0.5730 (0.1039)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5758 ± 0.0696\n",
            "  95% CI:           [0.4894, 0.6623]\n",
            "  Variance:         0.004845\n",
            "  CV:               12.09%\n",
            "  Range:            [0.4743, 0.6457] (span: 0.1715)\n",
            "  Median (IQR):     0.5879 (0.0876)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5960 ± 0.0930\n",
            "  95% CI:           [0.4805, 0.7115]\n",
            "  Variance:         0.008653\n",
            "  CV:               15.61%\n",
            "  Range:            [0.4627, 0.7222] (span: 0.2595)\n",
            "  Median (IQR):     0.5895 (0.0396)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6266 ± 0.0513\n",
            "  95% CI:           [0.5629, 0.6903]\n",
            "  Variance:         0.002631\n",
            "  CV:               8.19%\n",
            "  Range:            [0.5834, 0.7105] (span: 0.1271)\n",
            "  Median (IQR):     0.6260 (0.0404)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE CROSS-VALIDATION RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Whisper Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.554±0.033 │ [0.513,0.595] │    6.0   │ 0.087    │ 0.556    │\n",
            "│ ROC AUC     │ 0.566±0.073 │ [0.476,0.656] │   12.8   │ 0.161    │ 0.582    │\n",
            "│ Sensitivity │ 0.579±0.035 │ [0.535,0.622] │    6.0   │ 0.086    │ 0.579    │\n",
            "│ Specificity │ 0.513±0.109 │ [0.378,0.649] │   21.3   │ 0.252    │ 0.551    │\n",
            "│ F1 Score    │ 0.614±0.027 │ [0.581,0.647] │    4.3   │ 0.065    │ 0.602    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n",
            "\n",
            "Traditional Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.580±0.065 │ [0.500,0.660] │   11.1   │ 0.173    │ 0.560    │\n",
            "│ ROC AUC     │ 0.609±0.071 │ [0.521,0.697] │   11.7   │ 0.159    │ 0.573    │\n",
            "│ Sensitivity │ 0.576±0.070 │ [0.489,0.662] │   12.1   │ 0.171    │ 0.588    │\n",
            "│ Specificity │ 0.596±0.093 │ [0.481,0.712] │   15.6   │ 0.259    │ 0.590    │\n",
            "│ F1 Score    │ 0.627±0.051 │ [0.563,0.690] │    8.2   │ 0.127    │ 0.626    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "DeepNN_small_results = crossval_compare_features(\"parkceleb_filtered\", min_audio_length=0.1, deep_features=\"Whisper Small\" ,model=DeepNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f23TWKETHfkp",
        "outputId": "892d5c88-e383-4acd-fd32-edf6246124d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features from: whisper_small_all_features.csv\n",
            "Loading features from: traditional_all_features.csv\n",
            "\n",
            "=== Processing Whisper Features with ImprovedDeepNN ===\n",
            "Feature dimension: 768\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_ImprovedDeepNN/fold_1.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_ImprovedDeepNN/fold_2.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 3 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_ImprovedDeepNN/fold_3.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_ImprovedDeepNN/fold_4.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_ImprovedDeepNN/fold_5.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Whisper Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5329 ± 0.0310\n",
            "  95% CI:           [0.4945, 0.5714]\n",
            "  Variance:         0.000959\n",
            "  CV:               5.81%\n",
            "  Range:            [0.4949, 0.5757] (span: 0.0808)\n",
            "  Median (IQR):     0.5358 (0.0323)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.5464 ± 0.0623\n",
            "  95% CI:           [0.4690, 0.6238]\n",
            "  Variance:         0.003885\n",
            "  CV:               11.41%\n",
            "  Range:            [0.4808, 0.6329] (span: 0.1521)\n",
            "  Median (IQR):     0.5612 (0.0761)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5217 ± 0.0776\n",
            "  95% CI:           [0.4254, 0.6180]\n",
            "  Variance:         0.006020\n",
            "  CV:               14.87%\n",
            "  Range:            [0.4015, 0.6042] (span: 0.2026)\n",
            "  Median (IQR):     0.5366 (0.0687)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5312 ± 0.1222\n",
            "  95% CI:           [0.3795, 0.6829]\n",
            "  Variance:         0.014929\n",
            "  CV:               23.00%\n",
            "  Range:            [0.3927, 0.6543] (span: 0.2615)\n",
            "  Median (IQR):     0.5543 (0.2229)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.5751 ± 0.0763\n",
            "  95% CI:           [0.4803, 0.6699]\n",
            "  Variance:         0.005828\n",
            "  CV:               13.28%\n",
            "  Range:            [0.4478, 0.6461] (span: 0.1982)\n",
            "  Median (IQR):     0.6038 (0.0419)\n",
            "\n",
            "=== Processing Traditional Features with ImprovedDeepNN ===\n",
            "Feature dimension: 29\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_1.pth\n",
            "Using loaded model for Traditional...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_2.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_3.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 4 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_4.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_5.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Traditional Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5668 ± 0.0746\n",
            "  95% CI:           [0.4742, 0.6594]\n",
            "  Variance:         0.005563\n",
            "  CV:               13.16%\n",
            "  Range:            [0.4574, 0.6380] (span: 0.1807)\n",
            "  Median (IQR):     0.5693 (0.0956)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.6037 ± 0.0858\n",
            "  95% CI:           [0.4972, 0.7103]\n",
            "  Variance:         0.007361\n",
            "  CV:               14.21%\n",
            "  Range:            [0.4929, 0.7016] (span: 0.2087)\n",
            "  Median (IQR):     0.5917 (0.1195)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5706 ± 0.1198\n",
            "  95% CI:           [0.4218, 0.7193]\n",
            "  Variance:         0.014357\n",
            "  CV:               21.00%\n",
            "  Range:            [0.4207, 0.7377] (span: 0.3170)\n",
            "  Median (IQR):     0.5459 (0.1130)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5876 ± 0.0458\n",
            "  95% CI:           [0.5307, 0.6445]\n",
            "  Variance:         0.002099\n",
            "  CV:               7.80%\n",
            "  Range:            [0.5394, 0.6498] (span: 0.1103)\n",
            "  Median (IQR):     0.5643 (0.0571)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6147 ± 0.0614\n",
            "  95% CI:           [0.5385, 0.6909]\n",
            "  Variance:         0.003769\n",
            "  CV:               9.99%\n",
            "  Range:            [0.5358, 0.6828] (span: 0.1471)\n",
            "  Median (IQR):     0.6352 (0.0864)\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE CROSS-VALIDATION RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Whisper Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.533±0.031 │ [0.494,0.571] │    5.8   │ 0.081    │ 0.536    │\n",
            "│ ROC AUC     │ 0.546±0.062 │ [0.469,0.624] │   11.4   │ 0.152    │ 0.561    │\n",
            "│ Sensitivity │ 0.522±0.078 │ [0.425,0.618] │   14.9   │ 0.203    │ 0.537    │\n",
            "│ Specificity │ 0.531±0.122 │ [0.380,0.683] │   23.0   │ 0.262    │ 0.554    │\n",
            "│ F1 Score    │ 0.575±0.076 │ [0.480,0.670] │   13.3   │ 0.198    │ 0.604    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n",
            "\n",
            "Traditional Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.567±0.075 │ [0.474,0.659] │   13.2   │ 0.181    │ 0.569    │\n",
            "│ ROC AUC     │ 0.604±0.086 │ [0.497,0.710] │   14.2   │ 0.209    │ 0.592    │\n",
            "│ Sensitivity │ 0.571±0.120 │ [0.422,0.719] │   21.0   │ 0.317    │ 0.546    │\n",
            "│ Specificity │ 0.588±0.046 │ [0.531,0.644] │    7.8   │ 0.110    │ 0.564    │\n",
            "│ F1 Score    │ 0.615±0.061 │ [0.538,0.691] │   10.0   │ 0.147    │ 0.635    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "ImprovedDeepNN_small_results = crossval_compare_features(\"parkceleb_filtered\", min_audio_length=0.1, deep_features=\"Whisper Small\", model=ImprovedDeepNN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF_small_results = crossval_compare_features(\"parkceleb_filtered\", min_audio_length=0.1, deep_features=\"Whisper Small\", model=RandomForestClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f5QZyexnMvG8",
        "outputId": "b2ae6531-1ef6-4e7e-953d-ac26d6e81cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features from: whisper_small_all_features.csv\n",
            "Loading features from: traditional_all_features.csv\n",
            "\n",
            "=== Processing Whisper Features with RandomForestClassifier ===\n",
            "Feature dimension: 768\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_RandomForestClassifier/fold_1.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_RandomForestClassifier/fold_2.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 3 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_RandomForestClassifier/fold_3.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_RandomForestClassifier/fold_4.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/whisper_small/Whisper_RandomForestClassifier/fold_5.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Whisper Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.6056 ± 0.0584\n",
            "  95% CI:           [0.5330, 0.6781]\n",
            "  Variance:         0.003414\n",
            "  CV:               9.65%\n",
            "  Range:            [0.5424, 0.6654] (span: 0.1230)\n",
            "  Median (IQR):     0.6123 (0.1098)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.5710 ± 0.0625\n",
            "  95% CI:           [0.4934, 0.6485]\n",
            "  Variance:         0.003904\n",
            "  CV:               10.94%\n",
            "  Range:            [0.4821, 0.6380] (span: 0.1559)\n",
            "  Median (IQR):     0.5691 (0.0768)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.7975 ± 0.1196\n",
            "  95% CI:           [0.6490, 0.9461]\n",
            "  Variance:         0.014310\n",
            "  CV:               15.00%\n",
            "  Range:            [0.5858, 0.8664] (span: 0.2806)\n",
            "  Median (IQR):     0.8515 (0.0397)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.3222 ± 0.0894\n",
            "  95% CI:           [0.2112, 0.4332]\n",
            "  Variance:         0.007994\n",
            "  CV:               27.75%\n",
            "  Range:            [0.2564, 0.4419] (span: 0.1856)\n",
            "  Median (IQR):     0.2609 (0.1380)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.7094 ± 0.0586\n",
            "  95% CI:           [0.6367, 0.7822]\n",
            "  Variance:         0.003435\n",
            "  CV:               8.26%\n",
            "  Range:            [0.6397, 0.7776] (span: 0.1379)\n",
            "  Median (IQR):     0.7222 (0.0894)\n",
            "\n",
            "=== Processing Traditional Features with RandomForestClassifier ===\n",
            "Feature dimension: 29\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_1.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_2.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 3 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_3.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_4.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_5.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Traditional Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5909 ± 0.0432\n",
            "  95% CI:           [0.5373, 0.6446]\n",
            "  Variance:         0.001868\n",
            "  CV:               7.31%\n",
            "  Range:            [0.5531, 0.6593] (span: 0.1061)\n",
            "  Median (IQR):     0.5786 (0.0459)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.6060 ± 0.0827\n",
            "  95% CI:           [0.5034, 0.7087]\n",
            "  Variance:         0.006835\n",
            "  CV:               13.64%\n",
            "  Range:            [0.5043, 0.7067] (span: 0.2023)\n",
            "  Median (IQR):     0.5960 (0.1158)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.7080 ± 0.1186\n",
            "  95% CI:           [0.5607, 0.8553]\n",
            "  Variance:         0.014073\n",
            "  CV:               16.76%\n",
            "  Range:            [0.5806, 0.8776] (span: 0.2970)\n",
            "  Median (IQR):     0.7257 (0.1354)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.4384 ± 0.0873\n",
            "  95% CI:           [0.3301, 0.5468]\n",
            "  Variance:         0.007620\n",
            "  CV:               19.91%\n",
            "  Range:            [0.3147, 0.5519] (span: 0.2372)\n",
            "  Median (IQR):     0.4461 (0.0668)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6777 ± 0.0293\n",
            "  95% CI:           [0.6414, 0.7140]\n",
            "  Variance:         0.000856\n",
            "  CV:               4.32%\n",
            "  Range:            [0.6552, 0.7246] (span: 0.0694)\n",
            "  Median (IQR):     0.6614 (0.0289)\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE CROSS-VALIDATION RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Whisper Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.606±0.058 │ [0.533,0.678] │    9.6   │ 0.123    │ 0.612    │\n",
            "│ ROC AUC     │ 0.571±0.062 │ [0.493,0.649] │   10.9   │ 0.156    │ 0.569    │\n",
            "│ Sensitivity │ 0.798±0.120 │ [0.649,0.946] │   15.0   │ 0.281    │ 0.851    │\n",
            "│ Specificity │ 0.322±0.089 │ [0.211,0.433] │   27.7   │ 0.186    │ 0.261    │\n",
            "│ F1 Score    │ 0.709±0.059 │ [0.637,0.782] │    8.3   │ 0.138    │ 0.722    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n",
            "\n",
            "Traditional Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.591±0.043 │ [0.537,0.645] │    7.3   │ 0.106    │ 0.579    │\n",
            "│ ROC AUC     │ 0.606±0.083 │ [0.503,0.709] │   13.6   │ 0.202    │ 0.596    │\n",
            "│ Sensitivity │ 0.708±0.119 │ [0.561,0.855] │   16.8   │ 0.297    │ 0.726    │\n",
            "│ Specificity │ 0.438±0.087 │ [0.330,0.547] │   19.9   │ 0.237    │ 0.446    │\n",
            "│ F1 Score    │ 0.678±0.029 │ [0.641,0.714] │    4.3   │ 0.069    │ 0.661    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DeepNN_med_results = crossval_compare_features(\"parkceleb_filtered\", min_audio_length=0.1, deep_features=\"Whisper Medium\" ,model=DeepNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ibNO0alhNATE",
        "outputId": "c542c0fa-3d3f-41f9-9cc8-a57e0b0f96a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features from: whisper_medium_all_features.csv\n",
            "Loading features from: traditional_all_features.csv\n",
            "\n",
            "=== Processing Whisper Features with DeepNN ===\n",
            "Feature dimension: 1024\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_DeepNN/fold_1.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_DeepNN/fold_2.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_DeepNN/fold_3.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_DeepNN/fold_4.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_DeepNN/fold_5.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Whisper Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5573 ± 0.0406\n",
            "  95% CI:           [0.5070, 0.6077]\n",
            "  Variance:         0.001644\n",
            "  CV:               7.28%\n",
            "  Range:            [0.5080, 0.6007] (span: 0.0927)\n",
            "  Median (IQR):     0.5738 (0.0622)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.5798 ± 0.0503\n",
            "  95% CI:           [0.5173, 0.6422]\n",
            "  Variance:         0.002529\n",
            "  CV:               8.67%\n",
            "  Range:            [0.5168, 0.6373] (span: 0.1205)\n",
            "  Median (IQR):     0.5655 (0.0699)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5698 ± 0.0695\n",
            "  95% CI:           [0.4836, 0.6561]\n",
            "  Variance:         0.004825\n",
            "  CV:               12.19%\n",
            "  Range:            [0.5017, 0.6779] (span: 0.1761)\n",
            "  Median (IQR):     0.5553 (0.0701)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5435 ± 0.0871\n",
            "  95% CI:           [0.4353, 0.6517]\n",
            "  Variance:         0.007589\n",
            "  CV:               16.03%\n",
            "  Range:            [0.4273, 0.6280] (span: 0.2007)\n",
            "  Median (IQR):     0.5768 (0.1311)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6113 ± 0.0267\n",
            "  95% CI:           [0.5781, 0.6444]\n",
            "  Variance:         0.000713\n",
            "  CV:               4.37%\n",
            "  Range:            [0.5817, 0.6504] (span: 0.0687)\n",
            "  Median (IQR):     0.6092 (0.0289)\n",
            "\n",
            "=== Processing Traditional Features with DeepNN ===\n",
            "Feature dimension: 29\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_1.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_2.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 3 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_3.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_4.pth\n",
            "Using loaded model for Traditional...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_DeepNN/fold_5.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Traditional Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5801 ± 0.0646\n",
            "  95% CI:           [0.4998, 0.6603]\n",
            "  Variance:         0.004180\n",
            "  CV:               11.15%\n",
            "  Range:            [0.5021, 0.6750] (span: 0.1729)\n",
            "  Median (IQR):     0.5602 (0.0496)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.6088 ± 0.0711\n",
            "  95% CI:           [0.5206, 0.6971]\n",
            "  Variance:         0.005053\n",
            "  CV:               11.68%\n",
            "  Range:            [0.5502, 0.7092] (span: 0.1590)\n",
            "  Median (IQR):     0.5730 (0.1039)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5758 ± 0.0696\n",
            "  95% CI:           [0.4894, 0.6623]\n",
            "  Variance:         0.004845\n",
            "  CV:               12.09%\n",
            "  Range:            [0.4743, 0.6457] (span: 0.1715)\n",
            "  Median (IQR):     0.5879 (0.0876)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5960 ± 0.0930\n",
            "  95% CI:           [0.4805, 0.7115]\n",
            "  Variance:         0.008653\n",
            "  CV:               15.61%\n",
            "  Range:            [0.4627, 0.7222] (span: 0.2595)\n",
            "  Median (IQR):     0.5895 (0.0396)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6266 ± 0.0513\n",
            "  95% CI:           [0.5629, 0.6903]\n",
            "  Variance:         0.002631\n",
            "  CV:               8.19%\n",
            "  Range:            [0.5834, 0.7105] (span: 0.1271)\n",
            "  Median (IQR):     0.6260 (0.0404)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE CROSS-VALIDATION RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Whisper Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.557±0.041 │ [0.507,0.608] │    7.3   │ 0.093    │ 0.574    │\n",
            "│ ROC AUC     │ 0.580±0.050 │ [0.517,0.642] │    8.7   │ 0.120    │ 0.566    │\n",
            "│ Sensitivity │ 0.570±0.069 │ [0.484,0.656] │   12.2   │ 0.176    │ 0.555    │\n",
            "│ Specificity │ 0.544±0.087 │ [0.435,0.652] │   16.0   │ 0.201    │ 0.577    │\n",
            "│ F1 Score    │ 0.611±0.027 │ [0.578,0.644] │    4.4   │ 0.069    │ 0.609    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n",
            "\n",
            "Traditional Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.580±0.065 │ [0.500,0.660] │   11.1   │ 0.173    │ 0.560    │\n",
            "│ ROC AUC     │ 0.609±0.071 │ [0.521,0.697] │   11.7   │ 0.159    │ 0.573    │\n",
            "│ Sensitivity │ 0.576±0.070 │ [0.489,0.662] │   12.1   │ 0.171    │ 0.588    │\n",
            "│ Specificity │ 0.596±0.093 │ [0.481,0.712] │   15.6   │ 0.259    │ 0.590    │\n",
            "│ F1 Score    │ 0.627±0.051 │ [0.563,0.690] │    8.2   │ 0.127    │ 0.626    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ImprovedDeepNN_med_results = crossval_compare_features(\"parkceleb_filtered\", min_audio_length=0.1, deep_features=\"Whisper Medium\", model=ImprovedDeepNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UUz6DeasNC2K",
        "outputId": "4f3e1ff6-69f7-4498-f452-e207ff18eaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features from: whisper_medium_all_features.csv\n",
            "Loading features from: traditional_all_features.csv\n",
            "\n",
            "=== Processing Whisper Features with ImprovedDeepNN ===\n",
            "Feature dimension: 1024\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_ImprovedDeepNN/fold_1.pth\n",
            "Using loaded model for Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_ImprovedDeepNN/fold_2.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_ImprovedDeepNN/fold_3.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 4 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_ImprovedDeepNN/fold_4.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_ImprovedDeepNN/fold_5.pth\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Whisper Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5501 ± 0.0559\n",
            "  95% CI:           [0.4807, 0.6195]\n",
            "  Variance:         0.003123\n",
            "  CV:               10.16%\n",
            "  Range:            [0.4829, 0.6083] (span: 0.1254)\n",
            "  Median (IQR):     0.5425 (0.0938)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.5841 ± 0.0703\n",
            "  95% CI:           [0.4969, 0.6714]\n",
            "  Variance:         0.004937\n",
            "  CV:               12.03%\n",
            "  Range:            [0.5056, 0.6593] (span: 0.1538)\n",
            "  Median (IQR):     0.5533 (0.1130)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5500 ± 0.0769\n",
            "  95% CI:           [0.4545, 0.6455]\n",
            "  Variance:         0.005915\n",
            "  CV:               13.98%\n",
            "  Range:            [0.4408, 0.6546] (span: 0.2138)\n",
            "  Median (IQR):     0.5489 (0.0394)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5505 ± 0.1344\n",
            "  95% CI:           [0.3836, 0.7174]\n",
            "  Variance:         0.018069\n",
            "  CV:               24.42%\n",
            "  Range:            [0.3845, 0.6747] (span: 0.2902)\n",
            "  Median (IQR):     0.6055 (0.2288)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.5989 ± 0.0376\n",
            "  95% CI:           [0.5522, 0.6457]\n",
            "  Variance:         0.001417\n",
            "  CV:               6.28%\n",
            "  Range:            [0.5593, 0.6418] (span: 0.0825)\n",
            "  Median (IQR):     0.6069 (0.0653)\n",
            "\n",
            "=== Processing Traditional Features with ImprovedDeepNN ===\n",
            "Feature dimension: 29\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_1.pth\n",
            "Using loaded model for Traditional...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_2.pth\n",
            "Using loaded model for Traditional...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 3 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_3.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 4 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_4.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7890/1414700993.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  save_data = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: experiment_results/models/traditional/Traditional_ImprovedDeepNN/fold_5.pth\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Traditional Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5668 ± 0.0746\n",
            "  95% CI:           [0.4742, 0.6594]\n",
            "  Variance:         0.005563\n",
            "  CV:               13.16%\n",
            "  Range:            [0.4574, 0.6380] (span: 0.1807)\n",
            "  Median (IQR):     0.5693 (0.0956)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.6037 ± 0.0858\n",
            "  95% CI:           [0.4972, 0.7103]\n",
            "  Variance:         0.007361\n",
            "  CV:               14.21%\n",
            "  Range:            [0.4929, 0.7016] (span: 0.2087)\n",
            "  Median (IQR):     0.5917 (0.1195)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.5706 ± 0.1198\n",
            "  95% CI:           [0.4218, 0.7193]\n",
            "  Variance:         0.014357\n",
            "  CV:               21.00%\n",
            "  Range:            [0.4207, 0.7377] (span: 0.3170)\n",
            "  Median (IQR):     0.5459 (0.1130)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.5876 ± 0.0458\n",
            "  95% CI:           [0.5307, 0.6445]\n",
            "  Variance:         0.002099\n",
            "  CV:               7.80%\n",
            "  Range:            [0.5394, 0.6498] (span: 0.1103)\n",
            "  Median (IQR):     0.5643 (0.0571)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6147 ± 0.0614\n",
            "  95% CI:           [0.5385, 0.6909]\n",
            "  Variance:         0.003769\n",
            "  CV:               9.99%\n",
            "  Range:            [0.5358, 0.6828] (span: 0.1471)\n",
            "  Median (IQR):     0.6352 (0.0864)\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE CROSS-VALIDATION RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Whisper Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.550±0.056 │ [0.481,0.619] │   10.2   │ 0.125    │ 0.542    │\n",
            "│ ROC AUC     │ 0.584±0.070 │ [0.497,0.671] │   12.0   │ 0.154    │ 0.553    │\n",
            "│ Sensitivity │ 0.550±0.077 │ [0.454,0.645] │   14.0   │ 0.214    │ 0.549    │\n",
            "│ Specificity │ 0.550±0.134 │ [0.384,0.717] │   24.4   │ 0.290    │ 0.605    │\n",
            "│ F1 Score    │ 0.599±0.038 │ [0.552,0.646] │    6.3   │ 0.083    │ 0.607    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n",
            "\n",
            "Traditional Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.567±0.075 │ [0.474,0.659] │   13.2   │ 0.181    │ 0.569    │\n",
            "│ ROC AUC     │ 0.604±0.086 │ [0.497,0.710] │   14.2   │ 0.209    │ 0.592    │\n",
            "│ Sensitivity │ 0.571±0.120 │ [0.422,0.719] │   21.0   │ 0.317    │ 0.546    │\n",
            "│ Specificity │ 0.588±0.046 │ [0.531,0.644] │    7.8   │ 0.110    │ 0.564    │\n",
            "│ F1 Score    │ 0.615±0.061 │ [0.538,0.691] │   10.0   │ 0.147    │ 0.635    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF_med_results = crossval_compare_features(\"parkceleb_filtered\", min_audio_length=0.1, deep_features=\"Whisper Medium\", model=RandomForestClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TpDnOof8NExJ",
        "outputId": "57f10731-dd0f-4fdd-a31e-4ffb37d655ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features from: whisper_medium_all_features.csv\n",
            "Loading features from: traditional_all_features.csv\n",
            "\n",
            "=== Processing Whisper Features with RandomForestClassifier ===\n",
            "Feature dimension: 1024\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_RandomForestClassifier/fold_1.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_RandomForestClassifier/fold_2.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 3 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_RandomForestClassifier/fold_3.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_RandomForestClassifier/fold_4.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/whisper_medium/Whisper_RandomForestClassifier/fold_5.pkl\n",
            "Using loaded model for Whisper...\n",
            "\n",
            "=== Whisper Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.6094 ± 0.0579\n",
            "  95% CI:           [0.5375, 0.6812]\n",
            "  Variance:         0.003350\n",
            "  CV:               9.50%\n",
            "  Range:            [0.5407, 0.6685] (span: 0.1278)\n",
            "  Median (IQR):     0.6304 (0.0967)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.6003 ± 0.0749\n",
            "  95% CI:           [0.5073, 0.6934]\n",
            "  Variance:         0.005612\n",
            "  CV:               12.48%\n",
            "  Range:            [0.4828, 0.6876] (span: 0.2048)\n",
            "  Median (IQR):     0.6017 (0.0345)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.7973 ± 0.1329\n",
            "  95% CI:           [0.6322, 0.9623]\n",
            "  Variance:         0.017668\n",
            "  CV:               16.67%\n",
            "  Range:            [0.5682, 0.8896] (span: 0.3214)\n",
            "  Median (IQR):     0.8485 (0.0823)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.3372 ± 0.0932\n",
            "  95% CI:           [0.2214, 0.4529]\n",
            "  Variance:         0.008690\n",
            "  CV:               27.65%\n",
            "  Range:            [0.2601, 0.4607] (span: 0.2006)\n",
            "  Median (IQR):     0.2773 (0.1406)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.7108 ± 0.0579\n",
            "  95% CI:           [0.6390, 0.7827]\n",
            "  Variance:         0.003353\n",
            "  CV:               8.15%\n",
            "  Range:            [0.6481, 0.7786] (span: 0.1305)\n",
            "  Median (IQR):     0.7360 (0.0871)\n",
            "\n",
            "=== Processing Traditional Features with RandomForestClassifier ===\n",
            "Feature dimension: 29\n",
            "Class distribution: [5239 8614]\n",
            "\n",
            "=== Fold 1 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_1.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 2 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_2.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 3 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_3.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 4 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_4.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Fold 5 ===\n",
            "Model loaded from: experiment_results/models/traditional/Traditional_RandomForestClassifier/fold_5.pkl\n",
            "Using loaded model for Traditional...\n",
            "\n",
            "=== Traditional Features - Comprehensive Statistics ===\n",
            "\n",
            "Accuracy:\n",
            "  Mean ± SD:        0.5909 ± 0.0432\n",
            "  95% CI:           [0.5373, 0.6446]\n",
            "  Variance:         0.001868\n",
            "  CV:               7.31%\n",
            "  Range:            [0.5531, 0.6593] (span: 0.1061)\n",
            "  Median (IQR):     0.5786 (0.0459)\n",
            "\n",
            "ROC AUC:\n",
            "  Mean ± SD:        0.6060 ± 0.0827\n",
            "  95% CI:           [0.5034, 0.7087]\n",
            "  Variance:         0.006835\n",
            "  CV:               13.64%\n",
            "  Range:            [0.5043, 0.7067] (span: 0.2023)\n",
            "  Median (IQR):     0.5960 (0.1158)\n",
            "\n",
            "Sensitivity (Recall):\n",
            "  Mean ± SD:        0.7080 ± 0.1186\n",
            "  95% CI:           [0.5607, 0.8553]\n",
            "  Variance:         0.014073\n",
            "  CV:               16.76%\n",
            "  Range:            [0.5806, 0.8776] (span: 0.2970)\n",
            "  Median (IQR):     0.7257 (0.1354)\n",
            "\n",
            "Specificity:\n",
            "  Mean ± SD:        0.4384 ± 0.0873\n",
            "  95% CI:           [0.3301, 0.5468]\n",
            "  Variance:         0.007620\n",
            "  CV:               19.91%\n",
            "  Range:            [0.3147, 0.5519] (span: 0.2372)\n",
            "  Median (IQR):     0.4461 (0.0668)\n",
            "\n",
            "F1 Score:\n",
            "  Mean ± SD:        0.6777 ± 0.0293\n",
            "  95% CI:           [0.6414, 0.7140]\n",
            "  Variance:         0.000856\n",
            "  CV:               4.32%\n",
            "  Range:            [0.6552, 0.7246] (span: 0.0694)\n",
            "  Median (IQR):     0.6614 (0.0289)\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE CROSS-VALIDATION RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Whisper Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.609±0.058 │ [0.537,0.681] │    9.5   │ 0.128    │ 0.630    │\n",
            "│ ROC AUC     │ 0.600±0.075 │ [0.507,0.693] │   12.5   │ 0.205    │ 0.602    │\n",
            "│ Sensitivity │ 0.797±0.133 │ [0.632,0.962] │   16.7   │ 0.321    │ 0.848    │\n",
            "│ Specificity │ 0.337±0.093 │ [0.221,0.453] │   27.6   │ 0.201    │ 0.277    │\n",
            "│ F1 Score    │ 0.711±0.058 │ [0.639,0.783] │    8.1   │ 0.131    │ 0.736    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n",
            "\n",
            "Traditional Features Summary:\n",
            "┌─────────────┬─────────────┬───────────────┬──────────┬──────────┬──────────┐\n",
            "│ Metric      │ Mean±SD     │ 95% CI        │ CV (%)   │ Range    │ Median   │\n",
            "├─────────────┼─────────────┼───────────────┼──────────┼──────────┼──────────┤\n",
            "│ Accuracy    │ 0.591±0.043 │ [0.537,0.645] │    7.3   │ 0.106    │ 0.579    │\n",
            "│ ROC AUC     │ 0.606±0.083 │ [0.503,0.709] │   13.6   │ 0.202    │ 0.596    │\n",
            "│ Sensitivity │ 0.708±0.119 │ [0.561,0.855] │   16.8   │ 0.297    │ 0.726    │\n",
            "│ Specificity │ 0.438±0.087 │ [0.330,0.547] │   19.9   │ 0.237    │ 0.446    │\n",
            "│ F1 Score    │ 0.678±0.029 │ [0.641,0.714] │    4.3   │ 0.069    │ 0.661    │\n",
            "└─────────────┴─────────────┴───────────────┴──────────┴──────────┴──────────┘\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtenXgkUM34r"
      },
      "source": [
        "# Sanity checks\n",
        "I messed up the save to csv part of whisper feature generation, so I had to fix it. That's what the code below is for. The function is also fixed now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV2aBcE7M53w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc11c0d6-f5d2-467e-9282-e5d4a2cedf78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique speaker IDs: ['pd_01' 'pd_03' 'pd_05' 'pd_06' 'pd_07' 'pd_08' 'pd_10' 'pd_11' 'pd_12'\n",
            " 'pd_13' 'pd_14' 'pd_16' 'pd_17' 'pd_18' 'pd_19' 'pd_20' 'pd_23' 'pd_24'\n",
            " 'pd_25' 'pd_27' 'pd_28' 'pd_29' 'pd_30' 'pd_31' 'pd_32' 'pd_33' 'pd_34'\n",
            " 'pd_35' 'pd_36' 'pd_37' 'pd_38' 'cn_01' 'cn_03' 'cn_05' 'cn_06' 'cn_07'\n",
            " 'cn_08' 'cn_10' 'cn_11' 'cn_12' 'cn_13' 'cn_14' 'cn_16' 'cn_17' 'cn_18'\n",
            " 'cn_19' 'cn_20' 'cn_23' 'cn_24' 'cn_25' 'cn_27' 'cn_28' 'cn_29' 'cn_30'\n",
            " 'cn_31' 'cn_32' 'cn_33' 'cn_34' 'cn_35' 'cn_36' 'cn_37' 'cn_38']\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"whisper_small_all_features.csv\")\n",
        "print(\"Unique speaker IDs:\", df['id'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmc4pCkrM8W8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "baa3166c-b991-45b0-a141-d3052f063183"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shutil' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import shutil\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241m.\u001b[39mcopy2(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper_all_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper_all_features_BACKUP.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopy2(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraditional_all_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraditional_all_features_BACKUP.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
          ]
        }
      ],
      "source": [
        "# import shutil\n",
        "shutil.copy2(\"whisper_all_features.csv\", \"whisper_all_features_BACKUP.csv\")\n",
        "shutil.copy2(\"traditional_all_features.csv\", \"traditional_all_features_BACKUP.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieh1zB8gNE8T"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"whisper_all_features.csv\")\n",
        "print(\"PD count:\", df[df['label'] == 1].shape[0])\n",
        "print(\"CN count:\", df[df['label'] == 0].shape[0])\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"traditional_all_features.csv\")\n",
        "print(\"PD count:\", df[df['label'] == 1].shape[0])\n",
        "print(\"CN count:\", df[df['label'] == 0].shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpo2UKDDM3tk"
      },
      "outputs": [],
      "source": [
        "def fix_labels_in_csv(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Create labels based on 'id' column\n",
        "    df['label'] = df['id'].str.contains('pd', case=False).astype(int)\n",
        "\n",
        "    # Save fixed CSV (backup original first!)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"Updated labels in {csv_path}. Class distribution: {df['label'].value_counts().to_dict()}\")\n",
        "\n",
        "# Apply to both feature CSVs\n",
        "fix_labels_in_csv(\"whisper_medium_all_features.csv\")\n",
        "# fix_labels_in_csv(\"traditional_all_features.csv\")\n",
        "\n",
        "df = pd.read_csv(\"whisper_medium_all_features.csv\")\n",
        "print(\"PD count:\", df[df['label'] == 1].shape[0])\n",
        "print(\"CN count:\", df[df['label'] == 0].shape[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}